{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting nanoid\n",
      "  Using cached nanoid-2.0.0-py3-none-any.whl.metadata (3.5 kB)\n",
      "Using cached nanoid-2.0.0-py3-none-any.whl (5.8 kB)\n",
      "Installing collected packages: nanoid\n",
      "Successfully installed nanoid-2.0.0\n"
     ]
    }
   ],
   "source": [
    "!pip install nanoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed amazon_vendor.csv\n",
      "Processed beauty_and_personal_care.csv\n",
      "Processed books_movies.csv\n",
      "Processed l4_collection.json\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import json\n",
    "import os\n",
    "import re\n",
    "import ast\n",
    "import pandas as pd\n",
    "from nanoid import generate\n",
    "\n",
    "def get_uuid():\n",
    "    alphanum = \"ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789\"\n",
    "    nano_id = generate(alphanum, size=4)\n",
    "    return nano_id\n",
    "\n",
    "# Define folder paths\n",
    "input_folder = \"input\"\n",
    "output_folder = \"output\"\n",
    "vendor_file = \"amazon_vendor.csv\"\n",
    "l4_file = \"l4_collection.json\"\n",
    "\n",
    "# Ensure output folder exists\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# Function to format category names\n",
    "def format_category_name(name):\n",
    "    \"\"\"Formats category names: lowercase, removes special chars, and replaces spaces with hyphens.\"\"\"\n",
    "    name = name.lower().replace(\"'\", \"\").replace(\"&\", \"and\").replace(\",\", \"\")\n",
    "    name = re.sub(r'\\s+', '-', name.strip())\n",
    "    return name\n",
    "\n",
    "\n",
    "# Load L4 collection data\n",
    "l4_lookup = {}\n",
    "l4_df = pd.read_json(os.path.join(input_folder, l4_file))\n",
    "for index, row in l4_df.iterrows():\n",
    "    # print(row)\n",
    "    l4_lookup[format_category_name(str(row[\"category\"]))] = row\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Load vendor data into a set for fast lookup\n",
    "vendor_data_lookup = set()\n",
    "vendor_data = {}\n",
    "vendor_data_df = pd.read_csv(os.path.join(input_folder, vendor_file))\n",
    "for index, row in vendor_data_df.iterrows():\n",
    "    categories = [\n",
    "        str(row[\"l1_cat\"]), str(row[\"l2_cat\"]), str(row[\"l3_cat\"]), str(row[\"l4_cat\"]),\n",
    "        str(row[\"l5_cat\"]), str(row[\"l6_cat\"]), str(row[\"l7_cat\"]), str(row[\"l8_cat\"]),\n",
    "        str(row[\"l9_cat\"]), str(row[\"l10_cat\"]), str(row[\"l11_cat\"])\n",
    "    ]\n",
    "\n",
    "    categories = [val for val in categories if val != 'nan']\n",
    "\n",
    "    key = ', '.join(categories)\n",
    "    vendor_data_lookup.add(key)\n",
    "    vendor_data[key] = row\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "output_data = []\n",
    "l4_output_data = []\n",
    "\n",
    "# Process each CSV file in the input folder\n",
    "for file_name in os.listdir(input_folder):\n",
    "    if file_name.endswith(\".csv\") and file_name not in [vendor_file]:  # Ignore vendor file\n",
    "        input_path = os.path.join(input_folder, file_name)\n",
    "        output_path = os.path.join(output_folder, f\"{os.path.splitext(file_name)[0]}.json\")\n",
    "\n",
    "        \n",
    "        with open(input_path, \"r\", encoding=\"utf-8\") as f:\n",
    "            reader = csv.DictReader(f)\n",
    "            for row in reader:\n",
    "                amazon_merged_entry_sd = row.get(\"Amazon Merged  Entry\", \"\").strip()\n",
    "              \n",
    "                amazon_merged_entry_for_this_row = []\n",
    "\n",
    "                try:\n",
    "                  amazon_merged_entry_for_this_row = ast.literal_eval(amazon_merged_entry_sd)\n",
    "        \n",
    "                except:\n",
    "                  continue\n",
    "\n",
    "                l4_sd = format_category_name(row.get(\"L4\", \"\").strip())\n",
    "                l4_object = l4_lookup[l4_sd]\n",
    "\n",
    "                amazon_ids_against_l4 = []\n",
    "\n",
    "                for amazon_merged_entry in amazon_merged_entry_for_this_row:\n",
    "                  if amazon_merged_entry in vendor_data_lookup:\n",
    "                    amazon_data = vendor_data[amazon_merged_entry]\n",
    "                    new_id = get_uuid()\n",
    "\n",
    "                    output_entry = {\n",
    "                        \"id\": new_id,\n",
    "                        \"l1_cat\": str(amazon_data[\"l1_cat\"]),\n",
    "                        \"l2_cat\": str(amazon_data[\"l2_cat\"]),\n",
    "                        \"l3_cat\": str(amazon_data[\"l3_cat\"]),\n",
    "                        \"l4_cat\": str(amazon_data[\"l4_cat\"]),\n",
    "                        \"l5_cat\": str(amazon_data[\"l5_cat\"]),\n",
    "                        \"l6_cat\": str(amazon_data[\"l6_cat\"]),\n",
    "                        \"l7_cat\": str(amazon_data[\"l7_cat\"]),\n",
    "                        \"l8_cat\": str(amazon_data[\"l8_cat\"]),\n",
    "                        \"l9_cat\": str(amazon_data[\"l9_cat\"]),\n",
    "                        \"l10_cat\": str(amazon_data[\"l10_cat\"]),\n",
    "                        \"l11_cat\": str(amazon_data[\"l11_cat\"]),\n",
    "                        \"sd_l4_id\": str(l4_object[\"id\"])\n",
    "                    }\n",
    "\n",
    "                    cleaned_output_entry = {k: v for k, v in output_entry.items() if v.lower() != \"nan\"}\n",
    "                    output_data.append(cleaned_output_entry)\n",
    "                    amazon_ids_against_l4.append(new_id)\n",
    "\n",
    "                l4_output_entry = {\n",
    "                    \"id\": str(l4_object[\"id\"]),\n",
    "                    \"l1_id\": str(l4_object[\"l1_id\"]),\n",
    "                    \"l2_id\": str(l4_object[\"l2_id\"]),\n",
    "                    \"l3_id\": str(l4_object[\"l3_id\"]),\n",
    "                    \"category\": str(l4_object[\"category\"]),\n",
    "                    \"amazon_category_ids\": amazon_ids_against_l4 \n",
    "                }\n",
    "                l4_output_data.append(l4_output_entry)\n",
    "\n",
    "    print(f\"Processed {file_name}\")\n",
    "\n",
    "# Save output JSON\n",
    "with open(os.path.join(output_folder, \"amazon_categories.json\"), \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(output_data, f, indent=4)\n",
    "\n",
    "# Save output JSON\n",
    "with open(os.path.join(output_folder, \"l4_output.json\"), \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(l4_output_data, f, indent=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
